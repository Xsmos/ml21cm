{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 改編ContextUnet及相關代碼，使其首先對二維的情況適用。並於diffusers.Unet2DModel作比較並加以優化。最後再改寫爲3維的情形。\n",
    "- 經試用diffusers的Unet2DModel，發現loss從0.3降到0.2但仍然很高，説明存在非Unet2DModel的問題可以優化\n",
    "- 改用diffusers的DDMPScheduler和DDPMPipeline后，loss降低至0.1以下，有時甚至可以低至0.004，可見我的代碼問題主要出在DDPM部分。DDPMScheduler部分比較簡短，似乎沒有問題，所以問題應該在DDPMPipeline裏某一部分代碼是我代碼欠缺的。\n",
    "- 我在DDPMScheduler部分有一個typo，導致beta_t一直很小，修正后loss從0.2能降低至0.02, 維持在0.1以下\n",
    "- 用diffusers的DDPMScheduler似乎效果要好一些，loss總是比我的DDPMScheduler要小一點。儅epoch為19時，前者的loss約0.02，後者loss約0.07。而且前者還支持3維圖像的加噪，不如直接用別人的輪子。但我想知道爲什麽我的loss會高一些。\n",
    "- 我意識到別人的DDPMScheduler在sample函數中沒有兼容輸入參數，所以歸根結底還是需要我的DDPMscheduler。不過我可以先用別人的來debug我的ContextUnet.\n",
    "- 我需要將我的ContextUnet擴展兼容不同維度的照片，畢竟我本身也需要和原文獻對比完了再拓展到三維的情形\n",
    "- 我已將我的ContextUnet轉成了2維的模式，與diffusers.Unet2DModel的loss=0.037相比，我的Unet的loss=0.07。同時我的Unet生成的圖像看上去很奇怪，説明我的Unet也有問題。我需要將代碼退回原Unet，並檢查問題所在。\n",
    "- 我將紅移方向的像素的數量限制在了64.以此比較兩個Unet的差別。經比較：\\\n",
    "Unet2DModel loss：0.03, 0.0655, 0.05, 0.02, 0.05\\\n",
    "ContextUnet loss: 0.1, 0.16, 0.1, 0.2186, 0.06\n",
    "- 我把ContextUnet退回到了原作者的版本，結果loss=0.05，輸出的照片也不錯。我主要的改動是改回了他原用的normalization函數，其中還有個參數swish。有時間我可以研究一下具體是哪裏影響了訓練的結果。另外我發現了要想tensorboard的圖綫獨立美觀，需要把他們放在不同的文件夾下\n",
    "- 經過驗證，GroupNorm比batchNorm效果要好\n",
    "- 已擴展爲接受不同維度的情形\n",
    "- 融合cond, guide_w, drop_out這些參數\n",
    "- 生成的21cm圖像該暗的地方不夠暗，似乎換成MNIST的數字圖像就沒問題\n",
    "- 我用diffusion模型生成MNIST的數字時發現，儘管生成的數據的範圍也存在負數數值，如-0.1,但畫出來的圖像卻是理想的黑色。數據的分佈與21cm的結果的分佈沒多大差別，我現在打算把代碼退回到21cm的情形\n",
    "- 我統一了ddpm21cm這個module，能統一實現訓練和生成樣本，但目前有個bug， sample時總是會cuda out of memory，然而單獨resume model並sample就不會。\n",
    "- 解決了，問題出在我忘了寫with torch.no_grad():\n",
    "- 接下來就是生成800個lightcones，與此同時研究如何計算global signal以及power spectrum\n",
    "- 儅訓練圖片的數量達到5000時，生成的圖片與檢測數據的相似程度很高"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "import h5py\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "# from datasets import Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "# from abc import ABC, abstractmethod\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "# from PIL import Image\n",
    "import os\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import copy\n",
    "from tqdm.auto import tqdm\n",
    "# from torchvision import transforms\n",
    "# from diffusers import UNet2DModel#, UNet3DConditionModel\n",
    "# from diffusers import DDPMScheduler\n",
    "from diffusers.utils import make_image_grid\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "from diffusers.optimization import get_cosine_schedule_with_warmup\n",
    "from accelerate import notebook_launcher, Accelerator\n",
    "from huggingface_hub import create_repo, upload_folder\n",
    "\n",
    "from load_h5 import Dataset4h5\n",
    "from context_unet import ContextUnet\n",
    "\n",
    "from huggingface_hub import notebook_login"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add noise:\n",
    "\n",
    "\\begin{align*}\n",
    "x_t &\\sim \\mathcal N\\left(\\sqrt{1-\\beta_t}\\ x_{t-1},\\ \\beta_t \\right) \\\\\n",
    "x_t &\\equiv \\sqrt{1-\\beta_t}\\ x_{t-1} + \\sqrt{\\beta_t}\\ \\epsilon\\\\\n",
    "\\epsilon &\\sim \\mathcal N(0,1)\\\\\n",
    "\\alpha_t & \\equiv 1 - \\beta_t\\\\\n",
    "& ...\\\\\n",
    "x_t &= \\sqrt{\\bar {\\alpha_t}} x_0 + \\epsilon\\ \\sqrt{1 - \\bar{\\alpha_t}}\\\\\n",
    "\\bar {\\alpha_t} &\\equiv \\prod_{i=1}^t \\alpha_i\\\\\n",
    "&= \\exp\\left({\\ln{\\prod_{i=1}^t \\alpha_i}}\\right)\\\\\n",
    "&= \\exp\\left({\\sum_{i=1}^t\\ln{ \\alpha_i}}\\right)\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DDPMScheduler(nn.Module):\n",
    "    def __init__(self, betas: tuple, num_timesteps: int, img_shape: list, device='cpu'):\n",
    "        super().__init__()\n",
    "        \n",
    "        beta_1, beta_T = betas\n",
    "        assert 0 < beta_1 <= beta_T <= 1, \"ensure 0 < beta_1 <= beta_T <= 1\"\n",
    "        self.device = device\n",
    "        self.num_timesteps = num_timesteps\n",
    "        self.img_shape = img_shape\n",
    "        self.beta_t = torch.linspace(beta_1, beta_T, self.num_timesteps) #* (beta_T-beta_1) + beta_1\n",
    "        self.beta_t = self.beta_t.to(self.device)\n",
    "\n",
    "        # self.drop_prob = drop_prob\n",
    "        # self.cond = cond\n",
    "        self.alpha_t = 1 - self.beta_t\n",
    "        # self.bar_alpha_t = torch.exp(torch.cumsum(torch.log(self.alpha_t), dim=0))\n",
    "        self.bar_alpha_t = torch.cumprod(self.alpha_t, dim=0)\n",
    "\n",
    "    def add_noise(self, clean_images):\n",
    "        shape = clean_images.shape\n",
    "        expand = torch.ones(len(shape)-1, dtype=int)\n",
    "        # ts_expand = ts.view(ts.shape[0], *expand.tolist())\n",
    "        # expand = [1 for i in range(len(shape)-1)]\n",
    "\n",
    "        noise = torch.randn_like(clean_images).to(self.device)\n",
    "        ts = torch.randint(0, self.num_timesteps, (shape[0],)).to(self.device)\n",
    "                \n",
    "        # test_expand = test.view(test.shape[0],*expand)\n",
    "        # extend_dim = [None for i in range(shape.dim()-1)]\n",
    "        noisy_images = (\n",
    "            clean_images * torch.sqrt(self.bar_alpha_t[ts]).view(shape[0], *expand.tolist())\n",
    "            + noise * torch.sqrt(1-self.bar_alpha_t[ts]).view(shape[0], *expand.tolist())\n",
    "            )\n",
    "        # print(x_t.shape)\n",
    "\n",
    "        return noisy_images, noise, ts\n",
    "\n",
    "    def sample(self, nn_model, params, device, guide_w = 0):\n",
    "        n_sample = len(params) #params.shape[0]\n",
    "        # print(\"params.shape[0], len(params)\", params.shape[0], len(params))\n",
    "        x_i = torch.randn(n_sample, *self.img_shape).to(device)\n",
    "        # print(\"x_i.shape =\", x_i.shape)\n",
    "        # print(\"x_i.shape =\", x_i.shape)\n",
    "        if guide_w != -1:\n",
    "            c_i = params\n",
    "            uncond_tokens = torch.zeros(int(n_sample), params.shape[1]).to(device)\n",
    "            # uncond_tokens = torch.tensor(np.float32(np.array([0,0]))).to(device)\n",
    "            # uncond_tokens = uncond_tokens.repeat(int(n_sample),1)\n",
    "            c_i = torch.cat((c_i, uncond_tokens), 0)\n",
    "\n",
    "        x_i_entire = [] # keep track of generated steps in case want to plot something\n",
    "        # print(\"self.num_timesteps =\", self.num_timesteps)\n",
    "        # for i in range(self.num_timesteps, 0, -1):\n",
    "        # print(f'sampling!!!')\n",
    "        pbar_sample = tqdm(total=self.num_timesteps)\n",
    "        pbar_sample.set_description(\"Sampling\")\n",
    "        for i in reversed(range(0, self.num_timesteps)):\n",
    "            # print(f'sampling timestep {i:4d}',end='\\r')\n",
    "            t_is = torch.tensor([i]).to(device)\n",
    "            t_is = t_is.repeat(n_sample)\n",
    "\n",
    "            z = torch.randn(n_sample, *self.img_shape).to(device) if i > 0 else 0\n",
    "\n",
    "            if guide_w == -1:\n",
    "                # eps = nn_model(x_i, t_is, return_dict=False)[0]\n",
    "                eps = nn_model(x_i, t_is)\n",
    "                # x_i = 1/torch.sqrt(self.alpha_t[i])*(x_i-eps*self.beta_t[i]/torch.sqrt(1-self.bar_alpha_t[i])) + torch.sqrt(self.beta_t[i])*z\n",
    "            else:\n",
    "                # double batch\n",
    "                x_i = x_i.repeat(2, *torch.ones(len(self.img_shape), dtype=int).tolist())\n",
    "                t_is = t_is.repeat(2)\n",
    "\n",
    "                # split predictions and compute weighting\n",
    "                # print(\"nn_model input shape\", x_i.shape, t_is.shape, c_i.shape)\n",
    "                eps = nn_model(x_i, t_is, c_i)\n",
    "                eps1 = eps[:n_sample]\n",
    "                eps2 = eps[n_sample:]\n",
    "                eps = eps1 + guide_w*(eps1 - eps2)\n",
    "                # eps = (1+guide_w)*eps1 - guide_w*eps2\n",
    "                x_i = x_i[:n_sample]\n",
    "                # x_i = 1/torch.sqrt(self.alpha_t[i])*(x_i-eps*self.beta_t[i]/torch.sqrt(1-self.bar_alpha_t[i])) + torch.sqrt(self.beta_t[i])*z\n",
    "            \n",
    "            # print(\"x_i.shape =\", x_i.shape)\n",
    "            x_i = 1/torch.sqrt(self.alpha_t[i])*(x_i-eps*self.beta_t[i]/torch.sqrt(1-self.bar_alpha_t[i])) + torch.sqrt(self.beta_t[i])*z\n",
    "            \n",
    "            pbar_sample.update(1)\n",
    "            # pbar_sample.set_postfix(step=i)\n",
    "            \n",
    "            # print(\"x_i.shape =\", x_i.shape)\n",
    "            # store only part of the intermediate steps\n",
    "            if i%20==0:# or i==0:# or i<8:\n",
    "                x_i_entire.append(x_i.detach().cpu().numpy())\n",
    "        x_i = x_i.detach().cpu().numpy()\n",
    "        x_i_entire = np.array(x_i_entire)\n",
    "        return x_i, x_i_entire\n",
    "\n",
    "\n",
    "# ddpm_scheduler = DDPMScheduler((1e-4,0.02),10)\n",
    "# noisy_images, noise, ts = ddpm_scheduler.add_noise(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EMA:\n",
    "    def __init__(self, beta):\n",
    "        super().__init__()\n",
    "        self.beta = beta\n",
    "        self.step = 0\n",
    "\n",
    "    def update_model_average(self, ma_model, current_model):\n",
    "        for current_params, ma_params in zip(current_model.parameters(), ma_model.parameters()):\n",
    "            old_weight, up_weight = ma_params.data, current_params.data\n",
    "            ma_params.data = self.update_average(old_weight, up_weight)\n",
    "\n",
    "    def update_average(self, old, new):\n",
    "        if old is None:\n",
    "            return new\n",
    "        return old * self.beta + (1 - self.beta) * new\n",
    "\n",
    "    def step_ema(self, ema_model, model):\n",
    "        self.update_model_average(ema_model, model)\n",
    "        self.step += 1\n",
    "\n",
    "    def reset_parameters(self, ema_model, model):\n",
    "        ema_model.load_state_dict(model.state_dict())\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class TrainConfig:\n",
    "    ###########################\n",
    "    ## hardcoding these here ##\n",
    "    ###########################\n",
    "    push_to_hub = True\n",
    "    hub_model_id = \"Xsmos/ml21cm\"\n",
    "    hub_private_repo = False\n",
    "    dataset_name = \"/storage/home/hcoda1/3/bxia34/scratch/LEN128-DIM64-CUB8.h5\"\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    # repeat = 2\n",
    "\n",
    "    # dim = 2\n",
    "    dim = 2\n",
    "    stride = (2,2) if dim == 2 else (2,2,4)\n",
    "    num_image = 20000#15000#7000#25600#3000#10000#1000#10000#5000#2560#800#2560\n",
    "    batch_size = 50#20#2#100 # 10\n",
    "    n_epoch = 50#20#20#2#5#25 # 120\n",
    "    HII_DIM = 64\n",
    "    num_redshift = 64#512#256#256#64#512#128\n",
    "    channel = 1\n",
    "    img_shape = (channel, HII_DIM, num_redshift) if dim == 2 else (channel, HII_DIM, HII_DIM, num_redshift)\n",
    "\n",
    "    ranges_dict = dict(\n",
    "        params = {\n",
    "            0: [4, 6], # ION_Tvir_MIN\n",
    "            1: [10, 250], # HII_EFF_FACTOR\n",
    "            },\n",
    "        images = {\n",
    "            0: [0, 80], # brightness_temp\n",
    "            }\n",
    "        )\n",
    "\n",
    "    num_timesteps = 1000#1000 # 1000, 500; DDPM time steps\n",
    "    # n_sample = 24 # 64, the number of samples in sampling process\n",
    "    n_param = 2\n",
    "    guide_w = 0#-1#0#-1#0#-1#0.1#[0,0.1] #[0,0.5,2] strength of generative guidance\n",
    "    drop_prob = 0#0.28 # only takes effect when guide_w != -1\n",
    "    ema=True # whether to use ema\n",
    "    ema_rate=0.995\n",
    "\n",
    "    # seed = 0\n",
    "    # save_dir = './outputs/'\n",
    "\n",
    "    save_freq = 0#.1 # the period of sampling\n",
    "    # general parameters for the name and logger    \n",
    "    # device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    lrate = 1e-4\n",
    "    lr_warmup_steps = 0#5#00\n",
    "    output_dir = \"./outputs/\"\n",
    "    save_name = os.path.join(output_dir, 'model_state.pth')\n",
    "    # save_freq = 1 #10 # the period of saving model\n",
    "    # cond = True # if training using the conditional information\n",
    "    # lr_decay = False #True# if using the learning rate decay\n",
    "    resume = save_name # if resume from the trained checkpoints\n",
    "    # params_single = torch.tensor([0.2,0.80000023])\n",
    "    # params = torch.tile(params_single,(n_sample,1)).to(device)\n",
    "    # params =  params\n",
    "    # data_dir = './data' # data directory\n",
    "\n",
    "\n",
    "    mixed_precision = \"fp16\"\n",
    "    gradient_accumulation_steps = 1\n",
    "\n",
    "    # date = datetime.datetime.now().strftime(\"%m%d-%H%M\")\n",
    "    # run_name = f'{date}' # the unique name of each experiment\n",
    "\n",
    "# config = TrainConfig()\n",
    "# print(\"device =\", config.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @dataclass\n",
    "class DDPM21CM:\n",
    "    def __init__(self):\n",
    "        config = TrainConfig()\n",
    "        # date = datetime.datetime.now().strftime(\"%m%d-%H%M\")\n",
    "        config.run_name = datetime.datetime.now().strftime(\"%m%d-%H%M\") # the unique name of each experiment\n",
    "        self.config = config\n",
    "        # dataset = Dataset4h5(config.dataset_name, num_image=config.num_image, HII_DIM=config.HII_DIM, num_redshift=config.num_redshift, drop_prob=config.drop_prob, dim=config.dim)\n",
    "        # # self.shape_loaded = dataset.images.shape\n",
    "        # # print(\"shape_loaded =\", self.shape_loaded)\n",
    "        # self.dataloader = DataLoader(dataset, batch_size=config.batch_size, shuffle=True)\n",
    "        # del dataset\n",
    "        self.ddpm = DDPMScheduler(betas=(1e-4, 0.02), num_timesteps=config.num_timesteps, img_shape=config.img_shape, device=config.device)\n",
    "\n",
    "        # initialize the unet\n",
    "        self.nn_model = ContextUnet(n_param=config.n_param, image_size=config.HII_DIM, dim=config.dim, stride=config.stride)\n",
    "\n",
    "        if config.resume and os.path.exists(config.resume):\n",
    "            # resume_file = os.path.join(config.output_dir, f\"{config.resume}\")\n",
    "            self.nn_model.load_state_dict(torch.load(config.resume)['unet_state_dict'])\n",
    "            print(f\"resumed nn_model from {config.resume}\")\n",
    "        # nn_model = ContextUnet(n_param=1, image_size=28)\n",
    "        self.nn_model.train()\n",
    "        self.nn_model.to(self.ddpm.device)\n",
    "        # print(\"nn_model.device =\", ddpm.device)\n",
    "        # number of parameters to be trained\n",
    "        self.number_of_params = sum(x.numel() for x in self.nn_model.parameters())\n",
    "        print(f\"Number of parameters for nn_model: {self.number_of_params}\")\n",
    "\n",
    "        # whether to use ema\n",
    "        if config.ema:\n",
    "            self.ema = EMA(config.ema_rate)\n",
    "            if config.resume and os.path.exists(config.resume):\n",
    "                self.ema_model = ContextUnet(n_param=config.n_param, image_size=config.HII_DIM, dim=config.dim, stride=config.stride).to(config.device)\n",
    "                self.ema_model.load_state_dict(torch.load(config.resume)['ema_unet_state_dict'])\n",
    "                print(f\"resumed ema_model from {config.resume}\")\n",
    "            else:\n",
    "                self.ema_model = copy.deepcopy(self.nn_model).eval().requires_grad_(False)\n",
    "\n",
    "        self.optimizer = torch.optim.AdamW(self.nn_model.parameters(), lr=config.lrate)\n",
    "        self.lr_scheduler = get_cosine_schedule_with_warmup(\n",
    "            optimizer=self.optimizer,\n",
    "            num_warmup_steps=config.lr_warmup_steps,\n",
    "            num_training_steps=(int(config.num_image/config.batch_size) * config.n_epoch),\n",
    "            # num_training_steps=(len(self.dataloader) * config.n_epoch),\n",
    "        )\n",
    "\n",
    "        self.ranges_dict = config.ranges_dict\n",
    "\n",
    "    def load(self):\n",
    "        dataset = Dataset4h5(self.config.dataset_name, num_image=self.config.num_image, HII_DIM=self.config.HII_DIM, num_redshift=self.config.num_redshift, drop_prob=self.config.drop_prob, dim=self.config.dim, ranges_dict=self.ranges_dict)\n",
    "        # self.shape_loaded = dataset.images.shape\n",
    "        # print(\"shape_loaded =\", self.shape_loaded)\n",
    "        self.dataloader = DataLoader(dataset, batch_size=self.config.batch_size, shuffle=True)\n",
    "        # del dataset\n",
    "        # self.accelerate(self.config)\n",
    "        del dataset\n",
    "\n",
    "    # def accelerate(self):\n",
    "\n",
    "    def train(self):\n",
    "        ###################      \n",
    "        ## training loop ##\n",
    "        ###################\n",
    "        # plot_unet = True\n",
    "        self.load()\n",
    "        self.accelerator = Accelerator(\n",
    "            mixed_precision=self.config.mixed_precision,\n",
    "            gradient_accumulation_steps=self.config.gradient_accumulation_steps,\n",
    "            log_with=\"tensorboard\",\n",
    "            project_dir=os.path.join(self.config.output_dir, \"logs\"),\n",
    "        )\n",
    "        if self.accelerator.is_main_process:\n",
    "            if self.config.output_dir is not None:\n",
    "                os.makedirs(self.config.output_dir, exist_ok=True)\n",
    "            if self.config.push_to_hub:\n",
    "                self.repo_id = create_repo(\n",
    "                    repo_id=self.config.hub_model_id or Path(self.config.output_dir).name, exist_ok=True\n",
    "                ).repo_id\n",
    "            self.accelerator.init_trackers(f\"{self.config.run_name}\")\n",
    "\n",
    "        self.nn_model, self.optimizer, self.dataloader, self.lr_scheduler = \\\n",
    "            self.accelerator.prepare(\n",
    "            self.nn_model, self.optimizer, self.dataloader, self.lr_scheduler\n",
    "            )\n",
    "            \n",
    "        global_step = 0\n",
    "        for ep in range(self.config.n_epoch):\n",
    "            self.ddpm.train()\n",
    "\n",
    "            pbar_train = tqdm(total=len(self.dataloader), disable=not self.accelerator.is_local_main_process)\n",
    "            pbar_train.set_description(f\"Epoch {ep}\")\n",
    "            for i, (x, c) in enumerate(self.dataloader):\n",
    "                with self.accelerator.accumulate(self.nn_model):\n",
    "                    x = x.to(self.config.device)\n",
    "                    xt, noise, ts = self.ddpm.add_noise(x)\n",
    "                    \n",
    "                    if self.config.guide_w == -1:\n",
    "                        noise_pred = self.nn_model(xt, ts)\n",
    "                    else:\n",
    "                        c = c.to(self.config.device)\n",
    "                        noise_pred = self.nn_model(xt, ts, c)\n",
    "                    \n",
    "                    loss = F.mse_loss(noise, noise_pred)\n",
    "                    self.accelerator.backward(loss)\n",
    "                    self.accelerator.clip_grad_norm_(self.nn_model.parameters(), 1)\n",
    "                    self.optimizer.step()\n",
    "                    self.lr_scheduler.step()\n",
    "                    self.optimizer.zero_grad()\n",
    "\n",
    "                # ema update\n",
    "                if self.config.ema:\n",
    "                    self.ema.step_ema(self.ema_model, self.nn_model)\n",
    "\n",
    "                pbar_train.update(1)\n",
    "                logs = dict(\n",
    "                    loss=loss.detach().item(),\n",
    "                    lr=self.optimizer.param_groups[0]['lr'],\n",
    "                    step=global_step\n",
    "                )\n",
    "                pbar_train.set_postfix(**logs)\n",
    "\n",
    "                self.accelerator.log(logs, step=global_step)\n",
    "                global_step += 1\n",
    "\n",
    "            # if ep == config.n_epoch-1 or (ep+1)*config.save_freq==1:\n",
    "            self.save(ep)\n",
    "\n",
    "        del self.nn_model\n",
    "        if self.config.ema:\n",
    "            del self.ema_model\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    def save(self, ep):\n",
    "        # save model\n",
    "        if self.accelerator.is_main_process:\n",
    "            if ep == self.config.n_epoch-1 or (ep+1)*self.config.save_freq==1:\n",
    "                self.nn_model.eval()\n",
    "                with torch.no_grad():\n",
    "                    if self.config.push_to_hub:\n",
    "                        upload_folder(\n",
    "                            repo_id = self.repo_id,\n",
    "                            folder_path = \".\",#config.output_dir,\n",
    "                            commit_message = f\"{self.config.run_name}\",\n",
    "                            ignore_patterns = [\"step_*\", \"epoch_*\", \"*.npy\", \"__pycache__\"],\n",
    "                            )\n",
    "                    if self.config.save_name:\n",
    "                        model_state = {\n",
    "                            'epoch': ep,\n",
    "                            'unet_state_dict': self.nn_model.state_dict(),\n",
    "                            'ema_unet_state_dict': self.ema_model.state_dict(),\n",
    "                            }\n",
    "                        torch.save(model_state, self.config.save_name)\n",
    "                        print('saved model at ' + self.config.save_name)\n",
    "                        # print('saved model at ' + config.save_dir + f\"model_epoch_{ep}_test_{config.run_name}.pth\")\n",
    "\n",
    "    # def rescale(self, value, type='params', to_ranges=[0,1]):\n",
    "    #     for i, from_ranges in self.ranges_dict[type].items():\n",
    "    #         value[i] = (value[i] - from_ranges[0])/(from_ranges[1]-from_ranges[0]) # normalize\n",
    "    #         value[i] = \n",
    "    def rescale(self, value, ranges, to: list):\n",
    "        if value.ndim == 1:\n",
    "            value = value.view(-1,len(value))\n",
    "            \n",
    "        for i in range(np.shape(value)[1]):\n",
    "            value[:,i] = (value[:,i] - ranges[i][0]) / (ranges[i][1]-ranges[i][0])\n",
    "            # print(f\"i = {i}, value.min = {value[:,i].min()}, value.max = {value[:,i].max()}\")\n",
    "        value = value * (to[1]-to[0]) + to[0]\n",
    "        return value \n",
    "\n",
    "    def sample(self, file, params:torch.tensor=None, repeat=192, ema=False, entire=False):\n",
    "        # n_sample = params.shape[0]\n",
    "        \n",
    "        if params is None:\n",
    "            params = torch.tensor([0.20000000000000018, 0.5055875000000001])\n",
    "            params_backup = params.numpy().copy()\n",
    "        else:\n",
    "            params_backup = params.numpy().copy()\n",
    "            params = self.rescale(params, self.ranges_dict['params'], to=[0,1])\n",
    "\n",
    "        print(f\"sampling {repeat} images with normalized params = {params}\")\n",
    "        params = params.repeat(repeat,1)\n",
    "        assert params.dim() == 2, \"params must be a 2D torch.tensor\"\n",
    "        # print(\"params =\", params)\n",
    "        # print(\"params =\", params)\n",
    "        # print(\"len(params) =\", len(params))\n",
    "        # model = self.ema_model if ema else self.nn_model\n",
    "        # del self.ema_model, self.nn\n",
    "        # params = torch.tile(params, (n_sample,1)).to(device)\n",
    "\n",
    "        nn_model = ContextUnet(n_param=self.config.n_param, image_size=self.config.HII_DIM, dim=self.config.dim, stride=self.config.stride).to(self.config.device)\n",
    "        if ema:\n",
    "            nn_model.load_state_dict(torch.load(file)['ema_unet_state_dict'])\n",
    "        else:\n",
    "            nn_model.load_state_dict(torch.load(file)['unet_state_dict'])\n",
    "        print(f\"nn_model resumed from {file}\")\n",
    "        # nn_model = ContextUnet(n_param=1, image_size=28)\n",
    "        # nn_model.train()\n",
    "        nn_model.to(self.ddpm.device)\n",
    "        nn_model.eval()\n",
    "\n",
    "        # self.ema_model = ContextUnet(n_param=config.n_param, image_size=config.HII_DIM, dim=config.dim, stride=config.stride).to(config.device)\n",
    "        # self.ema_model.load_state_dict(torch.load(os.path.join(config.output_dir, f\"{config.resume}\"))['ema_unet_state_dict'])\n",
    "        # print(f\"resumed ema_model from {config.resume}\")\n",
    "\n",
    "        with torch.no_grad():\n",
    "            x_last, x_entire = self.ddpm.sample(\n",
    "                nn_model=nn_model, \n",
    "                params=params.to(self.config.device), \n",
    "                device=self.config.device, \n",
    "                guide_w=self.config.guide_w\n",
    "                )\n",
    "\n",
    "        # np.save(os.path.join(self.config.output_dir, f\"{self.config.run_name}{'ema' if ema else ''}.npy\"), x_last)\n",
    "        np.save(os.path.join(self.config.output_dir, f\"Tvir{params_backup[0]}-zeta{params_backup[1]}-N{self.config.num_image}{'ema' if ema else ''}.npy\"), x_last)\n",
    "\n",
    "        if entire:\n",
    "            np.save(os.path.join(self.config.output_dir, f\"Tvir{params_backup[0]}-zeta{params_backup[1]}-N{self.config.num_image}{'ema' if ema else ''}_entire.npy\"), x_last)\n",
    "# print(\"device =\", config.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "953f8c97563b4642b2a2c317d47b36dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- round 0 ---------------------\n",
      "Number of parameters for nn_model: 111048705\n",
      "run_name = 0630-2103\n",
      "Launching training on one GPU.\n",
      "dataset content: <KeysViewHDF5 ['brightness_temp', 'density', 'kwargs', 'params', 'redshifts_distances', 'seeds', 'xH_box']>\n",
      "51200 images can be loaded\n",
      "field.shape = (64, 64, 514)\n",
      "params keys = [b'ION_Tvir_MIN', b'HII_EFF_FACTOR']\n",
      "loading 20000 images randomly\n",
      "images loaded: (20000, 1, 64, 64)\n",
      "params loaded: (20000, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images rescaled to [-1.0, 1.221698522567749]\n",
      "params rescaled to [2.5516602907948993e-05, 0.9999958400767995]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fef9263018c4f29afec304cbc10fcec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b941a34a3504f478642c19ef4c27922",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1038ca61e174e40a5b05531a519d491",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5a234855e83409ca845f84aa6fb85c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed300c4a2fef4631b3566b4256a8c4f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31d7ce659cbd42bb84b406411f08024e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eaf25261ae4246049b0eb840d68b00f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed61e88aee0e48be957d13fb234ff2bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba2ddaa4c6f041718d5dace9a6c6c1fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0a8ad9853c440af9b2f6f13ec54b68d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "171672e3b54543dbaf502a8be9f4d5ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "310939e35813435eaf234925d3cd3182",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21cc0f82135c4f17b49187de7b7fca98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9420415ee7c64d4ea7c8e54d0c701316",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4172ee2ba56247f9a415f883a87c9a66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42b3deececec40ca87564c67da7f693d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a438adf1b34f46fbbc9fc9428dfb9200",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45e9416773aa4afcac6e470b7fd4cd2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46e451df95ab41ecbe55318b223b2c86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d667743a57644282a87349c354b10fba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8111295f9564e91ac85e7168fbda778",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a7b569c9c2643b5836718fa5974bde2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51c03adabcc74a04b049f180eddab9f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fa12dcf7df14b879417b3e70f574772",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0be918339144fd5be7e817b676b0580",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df78a7654fa84b438cf3ccff31b76e34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7132cc539f14a19b26977e10b8f6de8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0bbc437dd104790a9d9fe3fcc040f92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccb4a25e8e4c4ab4baefa6bed3170e0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "210d8f78255b40f78b7836e080420e75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ea47ab5cb9a4e53a82f1ecb7bc048c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8b3e3ec5acd48da9729e9f7bb64aaa6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d54c45893088451d864db1a281796bd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e45d916f42ea4cf9a4dbec63e8faf960",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7993693137341dfb5371caa09f0fce7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba34963c6e9a425882df1f876217a8e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38b5aca2065c433e895936c632f2c102",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "667e22f5eb544b61b94926c1f80c17d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5db4503ecc974d6abeff0829d69e1b19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "383cf929a7be475fbd316c1d92c20835",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18abbf10be204ffa898e0d4dc87455e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67cf3a5f5bf84dfcaa0fe183e2e0f1b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5de85fc62ce4a7292c8219763adbcdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0beef5c8b2a493185176e73f0c1dbd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "808e49050af2457e86e83846db30b365",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b02c2eeb52a14a86aa93ba5f0178febb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "028a8467cfc840bf8b1f3dd8a5e81138",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7bbbcb89aad4b58bc0645f5294495fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f9e094ab1d043a9aea56fe5a3ad8d6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a382819bc22a4270aef8999a8afa8970",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved model at ./outputs/model_state.pth\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # args = (config, nn_model, ddpm, optimizer, dataloader, lr_scheduler)\n",
    "    num_round = 1\n",
    "    for i in range(num_round):\n",
    "        print(f\" round {i} \".center(50, '-'))\n",
    "        ddpm21cm = DDPM21CM()\n",
    "        print(f\"run_name = {ddpm21cm.config.run_name}\")\n",
    "        notebook_launcher(ddpm21cm.train, num_processes=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 935M\n",
      "-rw-r--r--  1 bxia34 848M Jun 30 22:52 model_state.pth\n",
      "drwxr-xr-x 10 bxia34 4.0K Jun 30 21:17 \u001b[0m\u001b[01;34mlogs\u001b[0m/\n",
      "-rw-r--r--  1 bxia34 3.1M Jun 30 20:08 Tvir4.800000190734863-zeta131.34100341796875-N15000.npy\n",
      "-rw-r--r--  1 bxia34 3.1M Jun 30 19:50 Tvir5.4770002365112305-zeta200.0-N15000.npy\n",
      "-rw-r--r--  1 bxia34 3.1M Jun 30 19:32 Tvir4.698999881744385-zeta30.0-N15000.npy\n",
      "-rw-r--r--  1 bxia34 3.1M Jun 30 19:14 Tvir5.599999904632568-zeta19.03700065612793-N15000.npy\n",
      "-rw-r--r--  1 bxia34 3.1M Jun 30 18:57 Tvir4.400000095367432-zeta131.34100341796875-N15000.npy\n",
      "-rw-r--r--  1 bxia34 3.1M Jun 29 12:41 Tvir4.800000190734863-zeta131.34100341796875-N7000.npy\n",
      "-rw-r--r--  1 bxia34 3.1M Jun 29 12:23 Tvir5.4770002365112305-zeta200.0-N7000.npy\n",
      "-rw-r--r--  1 bxia34 3.1M Jun 29 12:06 Tvir4.698999881744385-zeta30.0-N7000.npy\n",
      "-rw-r--r--  1 bxia34 3.1M Jun 29 11:48 Tvir5.599999904632568-zeta19.03700065612793-N7000.npy\n",
      "-rw-r--r--  1 bxia34 3.1M Jun 29 11:30 Tvir4.400000095367432-zeta131.34100341796875-N7000.npy\n",
      "-rw-r--r--  1 bxia34 3.1M Jun 29 04:56 Tvir4.800000190734863-zeta131.34100341796875-N25600.npy\n",
      "-rw-r--r--  1 bxia34 3.1M Jun 29 04:38 Tvir5.4770002365112305-zeta200.0-N25600.npy\n",
      "-rw-r--r--  1 bxia34 3.1M Jun 29 04:21 Tvir4.698999881744385-zeta30.0-N25600.npy\n",
      "-rw-r--r--  1 bxia34 3.1M Jun 29 04:03 Tvir5.599999904632568-zeta19.03700065612793-N25600.npy\n",
      "-rw-r--r--  1 bxia34 3.1M Jun 29 03:45 Tvir4.400000095367432-zeta131.34100341796875-N25600.npy\n",
      "-rw-r--r--  1 bxia34 3.1M Jun 29 00:35 Tvir4.800000190734863-zeta131.34100341796875-N3000.npy\n",
      "-rw-r--r--  1 bxia34 3.1M Jun 29 00:17 Tvir5.4770002365112305-zeta200.0-N3000.npy\n",
      "-rw-r--r--  1 bxia34 3.1M Jun 28 23:59 Tvir4.698999881744385-zeta30.0-N3000.npy\n",
      "-rw-r--r--  1 bxia34 3.1M Jun 28 23:42 Tvir5.599999904632568-zeta19.03700065612793-N3000.npy\n",
      "-rw-r--r--  1 bxia34 3.1M Jun 28 23:20 Tvir4.400000095367432-zeta131.34100341796875-N3000.npy\n",
      "-rw-r--r--  1 bxia34 3.1M Jun 28 21:06 Tvir4.800000190734863-zeta131.34100341796875-N10000.npy\n",
      "-rw-r--r--  1 bxia34 3.1M Jun 28 20:49 Tvir5.4770002365112305-zeta200.0-N10000.npy\n",
      "-rw-r--r--  1 bxia34 3.1M Jun 28 20:31 Tvir4.698999881744385-zeta30.0-N10000.npy\n",
      "-rw-r--r--  1 bxia34 3.1M Jun 28 20:13 Tvir5.599999904632568-zeta19.03700065612793-N10000.npy\n",
      "-rw-r--r--  1 bxia34 3.1M Jun 28 19:56 Tvir4.400000095367432-zeta131.34100341796875-N10000.npy\n",
      "-rw-r--r--  1 bxia34 3.1M Jun 28 18:30 Tvir4.800000190734863-zeta131.34100341796875-N1000.npy\n",
      "-rw-r--r--  1 bxia34 3.1M Jun 28 18:13 Tvir5.4770002365112305-zeta200.0-N1000.npy\n",
      "-rw-r--r--  1 bxia34 3.1M Jun 28 17:55 Tvir4.698999881744385-zeta30.0-N1000.npy\n",
      "-rw-r--r--  1 bxia34 3.1M Jun 28 17:37 Tvir5.599999904632568-zeta19.03700065612793-N1000.npy\n",
      "-rw-r--r--  1 bxia34 3.1M Jun 28 17:20 Tvir4.400000095367432-zeta131.34100341796875-N1000.npy\n",
      "-rw-r--r--  1 bxia34 3.1M Jun 28 14:03 Tvir4.400000095367432-zeta131.34100341796875-N5000.npy\n",
      "-rw-r--r--  1 bxia34 3.1M Jun 10 18:58 Tvir4.800000190734863-zeta131.34100341796875-N5000.npy\n",
      "-rw-r--r--  1 bxia34 3.1M Jun 10 18:40 Tvir5.4770002365112305-zeta200.0-N5000.npy\n",
      "-rw-r--r--  1 bxia34 3.1M Jun 10 18:22 Tvir4.698999881744385-zeta30.0-N5000.npy\n",
      "-rw-r--r--  1 bxia34 3.1M Jun 10 18:05 Tvir5.599999904632568-zeta19.03700065612793-N5000.npy\n"
     ]
    }
   ],
   "source": [
    "ll -lth outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resumed nn_model from ./outputs/model_state.pth\n",
      "Number of parameters for nn_model: 111048705\n",
      "resumed ema_model from ./outputs/model_state.pth\n",
      "sampling 192 images with normalized params = tensor([[0.2000, 0.5056]])\n",
      "nn_model resumed from ./outputs/model_state.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c6ea22876794afebc250ac074675ba2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ddpm21cm = DDPM21CM()\n",
    "ddpm21cm.sample(\"./outputs/model_state.pth\", params=torch.tensor([4.4, 131.341]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resumed nn_model from ./outputs/model_state.pth\n",
      "Number of parameters for nn_model: 111048705\n",
      "resumed ema_model from ./outputs/model_state.pth\n",
      "sampling 192 images with normalized params = tensor([[0.8000, 0.0377]])\n",
      "nn_model resumed from ./outputs/model_state.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea6cb90bb0fb4b78b8d399845876a9e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ddpm21cm = DDPM21CM()\n",
    "ddpm21cm.sample(\"./outputs/model_state.pth\", params=torch.tensor((5.6, 19.037)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resumed nn_model from ./outputs/model_state.pth\n",
      "Number of parameters for nn_model: 111048705\n",
      "resumed ema_model from ./outputs/model_state.pth\n",
      "sampling 192 images with normalized params = tensor([[0.3495, 0.0833]])\n",
      "nn_model resumed from ./outputs/model_state.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f3a031f342d4c948c3424df826a76a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ddpm21cm = DDPM21CM()\n",
    "ddpm21cm.sample(\"./outputs/model_state.pth\", params=torch.tensor((4.699, 30)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resumed nn_model from ./outputs/model_state.pth\n",
      "Number of parameters for nn_model: 111048705\n",
      "resumed ema_model from ./outputs/model_state.pth\n",
      "sampling 192 images with normalized params = tensor([[0.7385, 0.7917]])\n",
      "nn_model resumed from ./outputs/model_state.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e745f7f80f26407aa5eef5f84ff9922c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ddpm21cm = DDPM21CM()\n",
    "ddpm21cm.sample(\"./outputs/model_state.pth\", params=torch.tensor((5.477, 200)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resumed nn_model from ./outputs/model_state.pth\n",
      "Number of parameters for nn_model: 111048705\n",
      "resumed ema_model from ./outputs/model_state.pth\n",
      "sampling 192 images with normalized params = tensor([[0.4000, 0.5056]])\n",
      "nn_model resumed from ./outputs/model_state.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "981510fbab6c4d88972badeed79e7d71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ddpm21cm = DDPM21CM()\n",
    "ddpm21cm.sample(\"./outputs/model_state.pth\", params=torch.tensor((4.8, 131.341)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 950M\n",
      "-rw-r--r-- 1 bxia34 pace-jw254 3.1M Jun 30 20:08 Tvir4.800000190734863-zeta131.34100341796875-N15000.npy\n",
      "-rw-r--r-- 1 bxia34 pace-jw254 3.1M Jun 30 19:50 Tvir5.4770002365112305-zeta200.0-N15000.npy\n",
      "-rw-r--r-- 1 bxia34 pace-jw254 3.1M Jun 30 19:32 Tvir4.698999881744385-zeta30.0-N15000.npy\n",
      "-rw-r--r-- 1 bxia34 pace-jw254 3.1M Jun 30 19:14 Tvir5.599999904632568-zeta19.03700065612793-N15000.npy\n",
      "-rw-r--r-- 1 bxia34 pace-jw254 3.1M Jun 30 18:57 Tvir4.400000095367432-zeta131.34100341796875-N15000.npy\n",
      "-rw-r--r-- 1 bxia34 pace-jw254 848M Jun 30 18:39 model_state.pth\n",
      "drwxr-xr-x 9 bxia34 pace-jw254 4.0K Jun 30 17:29 \u001b[0m\u001b[01;34mlogs\u001b[0m/\n",
      "-rw-r--r-- 1 bxia34 pace-jw254 3.1M Jun 29 12:41 Tvir4.800000190734863-zeta131.34100341796875-N7000.npy\n",
      "-rw-r--r-- 1 bxia34 pace-jw254 3.1M Jun 29 12:23 Tvir5.4770002365112305-zeta200.0-N7000.npy\n",
      "-rw-r--r-- 1 bxia34 pace-jw254 3.1M Jun 29 12:06 Tvir4.698999881744385-zeta30.0-N7000.npy\n",
      "-rw-r--r-- 1 bxia34 pace-jw254 3.1M Jun 29 11:48 Tvir5.599999904632568-zeta19.03700065612793-N7000.npy\n",
      "-rw-r--r-- 1 bxia34 pace-jw254 3.1M Jun 29 11:30 Tvir4.400000095367432-zeta131.34100341796875-N7000.npy\n",
      "-rw-r--r-- 1 bxia34 pace-jw254 3.1M Jun 29 04:56 Tvir4.800000190734863-zeta131.34100341796875-N25600.npy\n",
      "-rw-r--r-- 1 bxia34 pace-jw254 3.1M Jun 29 04:38 Tvir5.4770002365112305-zeta200.0-N25600.npy\n",
      "-rw-r--r-- 1 bxia34 pace-jw254 3.1M Jun 29 04:21 Tvir4.698999881744385-zeta30.0-N25600.npy\n",
      "-rw-r--r-- 1 bxia34 pace-jw254 3.1M Jun 29 04:03 Tvir5.599999904632568-zeta19.03700065612793-N25600.npy\n",
      "-rw-r--r-- 1 bxia34 pace-jw254 3.1M Jun 29 03:45 Tvir4.400000095367432-zeta131.34100341796875-N25600.npy\n",
      "-rw-r--r-- 1 bxia34 pace-jw254 3.1M Jun 29 00:35 Tvir4.800000190734863-zeta131.34100341796875-N3000.npy\n",
      "-rw-r--r-- 1 bxia34 pace-jw254 3.1M Jun 29 00:17 Tvir5.4770002365112305-zeta200.0-N3000.npy\n",
      "-rw-r--r-- 1 bxia34 pace-jw254 3.1M Jun 28 23:59 Tvir4.698999881744385-zeta30.0-N3000.npy\n",
      "-rw-r--r-- 1 bxia34 pace-jw254 3.1M Jun 28 23:42 Tvir5.599999904632568-zeta19.03700065612793-N3000.npy\n",
      "-rw-r--r-- 1 bxia34 pace-jw254 3.1M Jun 28 23:20 Tvir4.400000095367432-zeta131.34100341796875-N3000.npy\n",
      "-rw-r--r-- 1 bxia34 pace-jw254 3.1M Jun 28 21:06 Tvir4.800000190734863-zeta131.34100341796875-N10000.npy\n",
      "-rw-r--r-- 1 bxia34 pace-jw254 3.1M Jun 28 20:49 Tvir5.4770002365112305-zeta200.0-N10000.npy\n",
      "-rw-r--r-- 1 bxia34 pace-jw254 3.1M Jun 28 20:31 Tvir4.698999881744385-zeta30.0-N10000.npy\n",
      "-rw-r--r-- 1 bxia34 pace-jw254 3.1M Jun 28 20:13 Tvir5.599999904632568-zeta19.03700065612793-N10000.npy\n",
      "-rw-r--r-- 1 bxia34 pace-jw254 3.1M Jun 28 19:56 Tvir4.400000095367432-zeta131.34100341796875-N10000.npy\n",
      "-rw-r--r-- 1 bxia34 pace-jw254 3.1M Jun 28 18:30 Tvir4.800000190734863-zeta131.34100341796875-N1000.npy\n",
      "-rw-r--r-- 1 bxia34 pace-jw254 3.1M Jun 28 18:13 Tvir5.4770002365112305-zeta200.0-N1000.npy\n",
      "-rw-r--r-- 1 bxia34 pace-jw254 3.1M Jun 28 17:55 Tvir4.698999881744385-zeta30.0-N1000.npy\n",
      "-rw-r--r-- 1 bxia34 pace-jw254 3.1M Jun 28 17:37 Tvir5.599999904632568-zeta19.03700065612793-N1000.npy\n",
      "-rw-r--r-- 1 bxia34 pace-jw254 3.1M Jun 28 17:20 Tvir4.400000095367432-zeta131.34100341796875-N1000.npy\n",
      "-rw-r--r-- 1 bxia34 pace-jw254 3.1M Jun 28 14:03 Tvir4.400000095367432-zeta131.34100341796875-N5000.npy\n",
      "-rw-r--r-- 1 bxia34 pace-jw254 3.1M Jun 10 18:58 Tvir4.800000190734863-zeta131.34100341796875-N5000.npy\n",
      "-rw-r--r-- 1 bxia34 pace-jw254 3.1M Jun 10 18:40 Tvir5.4770002365112305-zeta200.0-N5000.npy\n",
      "-rw-r--r-- 1 bxia34 pace-jw254 3.1M Jun 10 18:22 Tvir4.698999881744385-zeta30.0-N5000.npy\n",
      "-rw-r--r-- 1 bxia34 pace-jw254 3.1M Jun 10 18:05 Tvir5.599999904632568-zeta19.03700065612793-N5000.npy\n"
     ]
    }
   ],
   "source": [
    "ls -lth outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config = TrainConfig()\n",
    "# def plot(filename, row=4, col=6):\n",
    "#     samples = np.load(filename)\n",
    "#     params = filename.split('guide_w')[-1][:-4]\n",
    "#     print(\"plotting\", samples.shape, params)\n",
    "#     plt.figure(figsize = (8,8))\n",
    "#     for i in range(24):\n",
    "#         plt.subplot(row,col,i+1)\n",
    "#         plt.imshow(samples[i,0,:,:], cmap='gray')#, vmin=-1, vmax=1)\n",
    "#         plt.xticks([])\n",
    "#         plt.yticks([])\n",
    "#         # plt.show()\n",
    "#     plt.suptitle(params)\n",
    "#     plt.tight_layout()\n",
    "#     plt.subplots_adjust(wspace=0, hspace=0) \n",
    "#     plt.show()\n",
    "#     # plt.savefig('outputs/'+params+'.png')\n",
    "#     # plt.close()\n",
    "#     # plt.imshow(images[0,0])\n",
    "#     # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot(\"outputs/0528-1433.npy\")\n",
    "# plot(\"outputs/0520-2323.npy\")\n",
    "# plot(\"outputs/0604-2353.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = np.load(\"outputs/0528-1433.npy\")\n",
    "# print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
